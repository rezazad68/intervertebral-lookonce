# [Intervertebral Disc Labeling With Learning Shape Information, A Look Once Approach](http://openaccess.thecvf.com/content_ICCVW_2019/papers/VRMI/Azad_Bi-Directional_ConvLSTM_U-Net_with_Densley_Connected_Convolutions_ICCVW_2019_paper.pdf)

Contexual attention network for medical image segmentation with state of the art results on skin lesion segmentation, multiple myeloma cell segmentation. This method incorpotrates the transformer module into a U-Net structure so as to concomitantly capture long-range dependancy along with resplendent local informations.
If this code helps with your research please consider citing the following paper:
</br>
> [R. Azad](https://scholar.google.com/citations?hl=en&user=Qb5ildMAAAAJ&view_op=list_works&sortby=pubdate), [Moein Heidari](https://scholar.google.com/citations?hl=en&user=CUHdgPcAAAAJ&view_op=list_works&sortby=pubdate), [Ehsan Adeli](https://scholar.google.com/citations?user=7NX_J_cAAAAJ&hl=en), [Julien Cohen-Adad](https://scholar.google.com/citations?user=6cAZ028AAAAJ) and [Dorit Merhof
](https://scholar.google.com/citations?user=JH5HObAAAAAJ&sortby=pubdate), "Intervertebral Disc Labeling With Learning Shape Information, A Look Once Approach", download [link](https://arxiv.org/pdf/1909.00166.pdf).



#### Please consider starring us, if you found it useful. Thanks

## Updates
- February 27, 2022: First release (Complete implemenation for [Spine Generic Dataset](https://www.nature.com/articles/s41597-021-00941-8) added.)

### Prerequisties and Run

This code has been implemented in python language using Pytorch libarary and tested in ubuntu, though should be compatible with related environment. The required libraries are included in the `requiremetns.txt` file. Please follow the bellow steps to train and evaluate the model.


1- Download the [Spine Generic Dataset](https://www.nature.com/articles/s41597-021-00941-8).

2- Run the `create_dataset.py` to gather the required data from the Spin Generic dataset.

3- Run `prepare_trainset.py` to creat the training and validation samples.

Notice: To avoid the above steps we have provided the processed data for all train, validation and test sets [here](https://drive.google.com/file/d/1z_mcIEoT_doyh_Hl53OaYWyplUel_-RT/view?usp=sharing) 

(should be around 150 MB) you can simply download it and continue with the rest steps. Please unzip the file in the `prepared_data` folder.

4- Run the `main.py` to train and evaluate the model. It only takes couple of hours to train with 5GB GPU memory. Use the following command with the related arguments to perform the required action:

A- Train and evaluate the model `python src/main.py`. You can use `--att true` to use the attention mechanisim.

B- Evaluate the model `python src/main.py --evaluate true` it will load the trained model and evalute it on the validation set.

C- You can run `make_res_gif.py` to creat a prediction video using the prediction images generated by `main.py` for the validation set.

D- You can change the number of stacked hourglass by `--stacks` argument. For more details check the arguments section in `main.py`.


5- Run the `test.py` to evaluate the model on the test set alongside with the metrics.





## Quick Overview
![Diagram of the proposed method](https://github.com/rezazad68/TMUnet/blob/main/Figures/Method%20(Main).png)

### Perceptual visualization of the proposed Contextual Attention module.
![Diagram of the proposed method](https://github.com/rezazad68/TMUnet/blob/main/Figures/Method%20(Submodule).png)


## Results
For evaluating the performance of the proposed method, Two challenging task in medical image segmentaion has been considered. In bellow, results of the proposed approach illustrated.
</br>
#### Task 1: SKin Lesion Segmentation


#### Performance Comparision on SKin Lesion Segmentation
In order to compare the proposed method with state of the art appraoches on SKin Lesion Segmentation, we considered Drive dataset.  

Methods (On ISIC 2017) |Dice-Score | Sensivity| Specificaty| Accuracy
------------ | -------------|----|-----------------|---- 
Ronneberger and et. all [U-net](https://arxiv.org/abs/1505.04597)       |0.8159	  |0.8172  |0.9680  |0.9164	  
Oktay et. all [Attention U-net](https://arxiv.org/abs/1804.03999)   |0.8082  |0.7998      |0.9776	  |0.9145
Lei et. all [DAGAN](https://www.sciencedirect.com/science/article/abs/pii/S1361841520300803)   |0.8425	  |0.8363       |0.9716	 |0.9304
Chen et. all [TransU-net](https://arxiv.org/abs/2102.04306)   |0.8123  |0.8263     |0.9577	  |0.9207
Asadi et. all [MCGU-Net](https://arxiv.org/abs/2003.05056)   |0.8927	  |	0.8502      |**0.9855**	  |0.9570	
Valanarasu et. all [MedT](https://arxiv.org/abs/2102.10662)   |0.8037	  |0.8064       |0.9546	  |0.9090
Wu et. all [FAT-Net](https://www.sciencedirect.com/science/article/abs/pii/S1361841521003728)   |0.8500	  |0.8392  |0.9725	  |0.9326
Azad et. all [Proposed TMUnet](https://github.com/rezazad68/TMUnet/edit/main/README.md)	  |**0.9164** 	| **0.9128**	|0.9789	  |**0.9660**
### For more results on ISIC 2018 and PH2 dataset, please refer to [the paper](https://arxiv.org/abs/1505.04597)


#### SKin Lesion Segmentation segmentation result on test data

![SKin Lesion Segmentation  result](https://github.com/rezazad68/TMUnet/blob/main/Figures/Skin%20lesion_segmentation.png)
(a) Input images. (b) Ground truth. (c) [U-net](https://arxiv.org/abs/2102.10662). (d) [Gated Axial-Attention](https://arxiv.org/abs/2102.10662). (e) Proposed method without a contextual attention module and (f) Proposed method.


## Multiple Myeloma Cell Segmentation

#### Performance Evalution on the Multiple Myeloma Cell Segmentation task

Methods | mIOU
------------ | -------------
[Frequency recalibration U-Net](https://openaccess.thecvf.com/content/ICCV2021W/CVAMD/papers/Azad_Deep_Frequency_Re-Calibration_U-Net_for_Medical_Image_Segmentation_ICCVW_2021_paper.pdf)	 |0.9392 
[XLAB Insights](https://arxiv.org/abs/2105.06238)	|0.9360
[DSC-IITISM](https://arxiv.org/abs/2105.06238)	|0.9356	  
[Multi-scale attention deeplabv3+](https://arxiv.org/abs/2105.06238)	 |0.9065	  
[U-Net](https://arxiv.org/abs/1505.04597)	  |0.7665
[Baseline](https://128.84.21.199/pdf/2003.05056.pdf)	  |0.9172
[Proposed](https://128.84.21.199/pdf/2003.05056.pdf)	  |**0.9395**



#### Multiple Myeloma Cell Segmentation results

![Multiple Myeloma Cell Segmentation result](https://github.com/rezazad68/TMUnet/blob/main/Figures/Cell_segmentation.png)

### Model weights
You can download the learned weights for each task in the following table. 

Task | Dataset |Learned weights
------------ | -------------|----
Skin Lesion Segmentation | [Drive](http://www.isi.uu.nl/Research/Databases/DRIVE/) |[TMUnet](https://drive.google.com/open?id=1_hpfspGGJcWyFcGLXkFUa4k1NdUyOSOb)
Multiple Myeloma Cell Segmentation | [ISIC2018](https://challenge.kitware.com/#phase/5abcb19a56357d0139260e53) |[TMUnet](https://drive.google.com/open?id=1EPRC-YmMk0AjHbdjoVy53jlSuweSbAHX)



### Query
All implementations are done by Reza Azad and Moein Heidari. For any query please contact us for more information.

```python
rezazad68@gmail.com
moeinheidari7829@gmail.com

```

